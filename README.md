# Combating-Misinformation-in-the-Era-of-Generative-AI-Models
It introduced a recent paper accepted by ACM MM 2023 Brave New Idea (BNI) track --- Combating Misinformation in the Era of Generative AI Models.
[acmmm23bni-combating misinformation in the era of generative AI models.pdf](https://github.com/xudanni0927/Combating-Misinformation-in-the-Era-of-Generative-AI-Models/files/13054303/acmmm23bni-combating.misinformation.in.the.era.of.generative.AI.models.pdf)

# Background:  
With social media perpetuating misinformation spreading, AI generative models rapidly producing multi-modal misinformation, and various misinformation types crafted by malicious actors, the future information environment's health is a cause for concern. 

**The Bleak Future: Gen-AI Misinformation's Impact on Information**

Firstly, the merging of multiple modalities makes it more difficult for users to differentiate between truth and fabrication. 

Furthermore, these models can also create personalized information by leveraging user data and capturing individual preferences and characteristics. For example, the study of Baird and colleagues works on personalized emotional audio generation. While this has benefits, generative models can also be used by malicious attackers to generate personalized misinformation. By understanding user preferences, browsing history, and online behavior, generative models can generate personalized news articles, product recommendations, or even social media posts that cater specifically to an individual's interests. This personalized information can be highly persuasive, increasing the likelihood of dissemination. 

Besides,  according to familiarity principle, people also tend to develop liking or disliking for things merely because they are familiar with them. 
In social media, the environment makes participants often encounter beliefs that amplify or reinforce their preexisting beliefs, known as echo chamber, it might cause participants circulates existing views without encountering opposing views, and reinforce their false cognition, known as confirmation bias.
Therefore, when large AI generative models created a number of similar misinformation, it is easy for social media participants to believe them, share them and reinforce the false information in the echo chamber.

![challenge-0807](https://github.com/xudanni0927/Combating-Misinformation-in-the-Era-of-Generative-AI-Models/assets/31812716/c960c04a-6813-421b-a5cb-fa2ff91dd2c1)


# Motivation: 
This paper examines the issue from psychological and societal perspectives, and explores the subtle manipulation traces found throughout the entire information life cycle.
The motivation of this work is from summarzing misinformation features during its whole life cycle. Specially, two main cues.
Firstly, during minformation creation stage, manipulation methods broke/lose patterns from authentic media, and leave unique cues. We summarized them as technical cues.
Then, people are easy to be effected by information with some characteristics, taking abnormal sharing and interaction behaviors. Therefore, in the stage of creation, spreading and consumption, psychological characteristics in the misinformation and user’s behaviors should be paid attention, forming psychological cues.
<img width="600" alt="image" src="https://github.com/xudanni0927/Combating-Misinformation-in-the-Era-of-Generative-AI-Models/assets/31812716/21e15bf2-0d3e-4c98-b35b-eefb2d6053a9">


# Framework
![image](https://github.com/xudanni0927/Combating-Misinformation-in-the-Era-of-Generative-AI-Models/assets/31812716/0131e7c1-faa0-4e32-8e88-5f03c3d91c83)


# Contribution: 
1. We investigate the potential misinformation situations that may emerge with the involvement of generative AI.
2. We identify influencing factors of misinformation from a social science perspective.
3. We proposes a conceptual multi-modal misinformation detection framework that analyzes manipulation traces at signal, perceptual, semantic, and human levels, emphasizing on the explainability and generalizability.

# Citation




